{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project pRF analysis results to pycortex surfaces\n",
    "Make sure you have created the pycortex entries for these individuals (https://github.com/VisionandCognition/NHP-pycortex)     \n",
    "Strategy:    \n",
    "- Load all (unthresholded) results into sorted numpy arrays with nibabel\n",
    "- Also create pycortex volume objects\n",
    "- Save them in an ordered dictionary\n",
    "- Define some functions for masking\n",
    "- Perform any additional post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cortex\n",
    "import nibabel as nib \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, shutil, copy\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set subject name and path to FitResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = 'Danny' # 'Danny'/'Eddy'\n",
    "FitResPath = os.path.join('/Users','chris','Documents','MRI_ANALYSIS','NHP-PRF','FitResults')\n",
    "ManualMaskPath = os.path.join('/Users','chris','Dropbox','GIT_Support','NHP-BIDS','manual-masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify which models and results to include\n",
    "Making changes here may or may not break subsequent as it relies on some of these things being present (e.g., R2, R2_1, and R2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Models = {\n",
    "    'dhrf' : ['linhrf_cv1_dhrf','linhrf_cv1_dhrf_neggain','csshrf_cv1_dhrf','doghrf_cv1_dhrf'],\n",
    "    'mhrf' : ['linhrf_cv1_mhrf','linhrf_cv1_mhrf_neggain','csshrf_cv1_mhrf','doghrf_cv1_mhrf'],\n",
    "    'names' : ['lin','lin_ng','css','dog'],\n",
    "}\n",
    "Res_type = ['ANG', 'ECC', 'EXPT', 'FWHM', 'GAIN', 'IMAG', 'REAL', 'RFS', 'X', 'Y', 'NAMP', 'SDRATIO']\n",
    "xfm = 'epi2surf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary to collect all FitResults in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be the structure of data collection\n",
    "FR = {\n",
    "    'subject' : subj,\n",
    "    'xfm' : xfm,\n",
    "    'mHRF' : {\n",
    "        'arr' : {},\n",
    "        'vol' : {},\n",
    "    },\n",
    "    'dHRF' : {\n",
    "        'arr' : {},\n",
    "        'vol' : {},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the dictionary with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mHRF: lin lin_ng css dog\n",
      "Processing dHRF: lin lin_ng css dog\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Model_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b958f7f305e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# bring it all together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mFR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'HRF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModel_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFitRes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mFR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'HRF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModel_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFitRes_vol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Model_names' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "for h in ['m','d']:\n",
    "    print('Processing ' + h + 'HRF:', end='')\n",
    "    for M in Models[h + 'hrf']:\n",
    "        # get model idx so we create a shorter variable name\n",
    "        midx = Models[h + 'hrf'].index(M)\n",
    "        print(' ' + Models['names'][midx], end='')\n",
    "        \n",
    "        # get the mean R2 map\n",
    "        volpath = os.path.join(FitResPath,'MRI',subj.lower(),M,'Sess-' + M + '_meanR2.nii.gz')\n",
    "        volpath1 = os.path.join(FitResPath,'MRI',subj.lower(),M,'Sess-' + M + '_R2_1.nii.gz')\n",
    "        volpath2 = os.path.join(FitResPath,'MRI',subj.lower(),M,'Sess-' + M + '_R2_2.nii.gz')\n",
    "\n",
    "        # load the results into numpy arrays with nibabel\n",
    "        R2 = np.array(nib.load(volpath).dataobj)\n",
    "        R2_1 = np.array(nib.load(volpath1).dataobj)\n",
    "        R2_2 = np.array(nib.load(volpath2).dataobj)\n",
    "\n",
    "        # convert to pycortex volumes\n",
    "        R2v = cortex.Volume(R2.transpose(2,1,0), subj, xfm)\n",
    "        R2_1v = cortex.Volume(R2_1.transpose(2,1,0), subj, xfm)\n",
    "        R2_2v = cortex.Volume(R2_2.transpose(2,1,0), subj, xfm)\n",
    "\n",
    "        # add info to dictionaries\n",
    "        # numpy arrays\n",
    "        FitRes = {\n",
    "            'R2' : R2,\n",
    "            'R2_1' : R2_1,\n",
    "            'R2_2' : R2_2\n",
    "            }\n",
    "        # pycortex volumes\n",
    "        FitRes_vol = {\n",
    "            'R2' : R2v,\n",
    "            'R2_1' : R2_1v,\n",
    "            'R2_2' : R2_2v\n",
    "            }\n",
    "\n",
    "        # also get othere results\n",
    "        for R in Res_type:\n",
    "            volpath = os.path.join(FitResPath,'MRI',subj.lower(),M,'TH_0', R + '_th0.nii.gz')\n",
    "            if os.path.exists(volpath):\n",
    "                FitRes[R] = np.array(nib.load(volpath).dataobj)\n",
    "                FitRes_vol[R] = cortex.Volume(FitRes[R].transpose(2,1,0), subj, xfm)\n",
    "\n",
    "        # bring it all together\n",
    "        FR[h + 'HRF']['arr'][Models['names'][midx]] = FitRes\n",
    "        FR[h + 'HRF']['vol'][Models['names'][midx]] = FitRes_vol\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Check in webviewer \n",
    "    cortex.webgl.show(data=FR['mHRF']['vol']['lin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some checks to see if this worked as expected\n",
    "Once we know it worked we can switch this off again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Inspect the result volumes (should be numpy arrays)\n",
    "    RR = copy.copy(FR['mHRF']['arr']['lin']['R2']) # copy the R2 values for some model\n",
    "    RR[RR < 5] ='nan' # threshold it to some level\n",
    "    \n",
    "    cortex.webgl.show(data=cortex.Volume(RR.transpose(2,1,0), subj, xfm)) # check to seeit worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to mask the results based on R2 values\n",
    "This function makes a deepcopy of the input dictionary to prevend overwriting it with masked data. Than masks it with the provided R2-threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2mask(DataDict,RTH):\n",
    "    DD = copy.deepcopy(DataDict) # copy the original data so it won't get overwritten\n",
    "    # mask the numpy arrays by inserting nan's\n",
    "    for hrf in ['mHRF','dHRF']:\n",
    "        for m in DD[hrf]['arr']:\n",
    "            # mask all available outputs except for R2\n",
    "            for res in DD[hrf]['arr'][m]:\n",
    "                if res is not 'R2':\n",
    "                    DD[hrf]['arr'][m][res][ DD[hrf]['arr'][m]['R2'] < RTH ] = 'nan'\n",
    "                    # also convert to the pycortex volume\n",
    "                    DD[hrf]['vol'][m][res] = cortex.Volume(DD[hrf]['arr'][m][res].transpose(2,1,0), DD['subject'], DD['xfm'])\n",
    "            # mask R2            \n",
    "            DD[hrf]['arr'][m]['R2'][ DD[hrf]['arr'][m]['R2'] < RTH ] = 'nan' \n",
    "            DD[hrf]['vol'][m]['R2'] = cortex.Volume(DD[hrf]['arr'][m]['R2'].transpose(2,1,0), DD['subject'], DD['xfm'])\n",
    "\n",
    "    return DD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the masking function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server on port 20129\n",
      "Stopping server\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    mFR = r2mask(FR,2)\n",
    "    cortex.webgl.show(data=mFR['mHRF']['vol']['lin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get D99 atlas information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read atlas labels\n",
    "D99_inFunc['labelpath'] = os.path.join(ManualMaskPath,'sub-' + subj.lower(),'atlas','D99_labeltable_reformat.txt')\n",
    "\n",
    "D99_inFunc['labels'] = {}\n",
    "with open(D99_inFunc['labelpath']) as f:\n",
    "    for line in f:\n",
    "        labelnum, label = line.strip().split(' ',1)\n",
    "        D99_inFunc['labels'][label.strip()] = int(labelnum)\n",
    "#print(D99_inFunc['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "D99_inFunc = {}\n",
    "D99_inFunc['path'] = os.path.join(ManualMaskPath,'sub-' + subj.lower(),'atlas','D99_in_' + subj + '_adj_inFunc.nii')\n",
    "D99_inFunc['arr'] = np.array(nib.load(D99_inFunc['path']).dataobj)\n",
    "D99_inFunc['vol'] = cortex.Volume(D99_inFunc['arr'].transpose(2,1,0), subj, xfm)\n",
    "\n",
    "if False:\n",
    "    cortex.webgl.show(data=D99_inFunc['vol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "D99_inFunc['labelpath'] = os.path.join(ManualMaskPath,'sub-' + subj.lower(),'atlas','D99_labeltable_reformat.txt')\n",
    "D99_inFunc['labels'] = {}\n",
    "with open(D99_inFunc['labelpath']) as f:\n",
    "    for line in f:\n",
    "        labelnum, label = line.strip().split(' ',1)\n",
    "        D99_inFunc['labels'][label.strip()] = int(labelnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that returns ROI names from voxel label number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roiname(LabelDict,LabelNum):\n",
    "    for name, number in LabelDict.items():\n",
    "        if number == LabelNum:\n",
    "            return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1\n"
     ]
    }
   ],
   "source": [
    "# test if the get_roiname function works\n",
    "if False:\n",
    "    roi = get_roiname(D99_inFunc['labels'],34)\n",
    "    print(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that returns data masked by ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roimask(DataDict,AtlasDict,rois):\n",
    "    # DataDict is the dictionary of results\n",
    "    # AtlasDict is a dictionary of D99 atlas info\n",
    "    # rois is a list of rois to include\n",
    "    \n",
    "    DD = copy.deepcopy(DataDict) # copy the original data so it won't get overwritten\n",
    "    AA = copy.deepcopy(AtlasDict) # copy the original data so it won't get overwritten\n",
    "    \n",
    "    # Create a mask that includes all rois in the list\n",
    "    mask = np.zeros(AA['arr'].shape)\n",
    "    for r in rois:\n",
    "        tmask = AA['arr']==AA['labels'][r]\n",
    "        mask = mask + tmask\n",
    "    mask[mask > 0]\n",
    "    \n",
    "    # mask the numpy arrays by inserting nan's\n",
    "    for hrf in ['mHRF','dHRF']:\n",
    "        for m in DD[hrf]['arr']:\n",
    "            # mask all available outputs except for R2\n",
    "            for res in DD[hrf]['arr'][m]:\n",
    "                DD[hrf]['arr'][m][res][ mask < 1 ] = 'nan'\n",
    "                # also convert to the pycortex volume\n",
    "                DD[hrf]['vol'][m][res] = cortex.Volume(DD[hrf]['arr'][m][res].transpose(2,1,0), DD['subject'], DD['xfm'])\n",
    "    return DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server on port 35378\n",
      "Stopping server\n"
     ]
    }
   ],
   "source": [
    "# test this function\n",
    "if True:\n",
    "    V1Res = roimask(FR,D99_inFunc,['V1'])\n",
    "    cortex.webgl.show(data=V1Res['mHRF']['vol']['lin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to interpolate (masked) surface results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpsurf(xxx,subject)\n",
    "    # import the pycortex surface tools\n",
    "    from cortex.polyutils import Surface as surf\n",
    "    \n",
    "    \n",
    "    \n",
    "    np.random.seed(1234) \n",
    "    subject = \"S1\"\n",
    "\n",
    "# First we need to import the surfaces for this subject\n",
    "lsurf, rsurf = [Surface(*d) for d in cortex.db.get_surf(subject, \"fiducial\")]\n",
    "\n",
    "# Let's choose a few points and generate data for them\n",
    "selected_pts = np.arange(len(lsurf.pts), step=5000)\n",
    "num_selected_pts = len(selected_pts)\n",
    "sparse_data = np.random.randn(num_selected_pts)\n",
    "\n",
    "# Then interpolate\n",
    "interp_data = lsurf.interp(selected_pts, sparse_data)\n",
    "\n",
    "# Plot the result\n",
    "# interp_data is only for the left hemisphere, but the Vertex constructor\n",
    "# infers that and fills the right hemisphere with zeros\n",
    "interp_vertex = cortex.Vertex(interp_data[:,0], subject, \n",
    "                              vmin=-2, vmax=2, cmap='RdBu_r')\n",
    "cortex.quickshow(interp_vertex, with_labels=False, with_rois=False)\n",
    "\n",
    "\n",
    "# plot the locations of the points we selected originally\n",
    "\n",
    "# nudge=True puts both left and right hemispheres in the same space, moving them\n",
    "# so that they don't overlap. These are the coordinates used in quickflat\n",
    "(lflatpts, lpolys), (rflatpts, rpolys) = cortex.db.get_surf(subject, \"flat\", \n",
    "                                                            nudge=True)\n",
    "\n",
    "ax = plt.gca()\n",
    "# zorder is set to 10 to make sure points go on top of other quickflat layers\n",
    "ax.scatter(lflatpts[selected_pts,0], lflatpts[selected_pts,1], s=50, \n",
    "           c=sparse_data, vmin=-2, vmax=2, cmap=plt.cm.RdBu_r, zorder=10)\n",
    "\n",
    "\n",
    "# the interpolate function can also handle multiple dimensions at the same time\n",
    "# (this takes a while to run for no plotting, and thus is commented out)\n",
    "#sparse_data_2d = np.random.randn(10, num_selected_pts)\n",
    "#interp_data_2d = lsurf.interp(selected_pts, sparse_data_2d)\n",
    "\n",
    "# > interp_data_2d.shape\n",
    "# (152893, 10)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
